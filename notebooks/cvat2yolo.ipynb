{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "177437bd-9432-4afe-be91-6f1bc4c70599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os import makedirs\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path, PosixPath\n",
    "import cv2\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from shutil import copy2\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as ntqdm\n",
    "from random import shuffle\n",
    "\n",
    "from numpy.typing import ArrayLike\n",
    "from typing import Any, Iterable, List, Tuple\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3ff114-53d5-406b-896f-5762f021841f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Yolo format \n",
    "\n",
    "dataset.yaml\n",
    "├── images\n",
    "│   ├── test\n",
    "│   ├── train\n",
    "│   └── val\n",
    "└── labels\n",
    "    ├── test\n",
    "    ├── train\n",
    "    └── val\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Bbox:\n",
    "    def __init__(self, xyxy: list | tuple, label: int):\n",
    "        self.x1 = int(xyxy[0])\n",
    "        self.y1 = int(xyxy[1])\n",
    "        self.x2 = int(xyxy[2])\n",
    "        self.y2 = int(xyxy[3])\n",
    "        self.label = label\n",
    "        # Fixme: Adapt label to COCO format in future.\n",
    "        self.pt1 = (self.x1, self.y1)\n",
    "        self.pt2 = (self.x2, self.y2)\n",
    "        self.width = abs(self.x2 - self.x1)\n",
    "        self.height = abs(self.y2 - self.y1)\n",
    "\n",
    "    def to_coco(self) -> List[int]:\n",
    "        return [self.x1, self.y1, self.width, self.height]\n",
    "\n",
    "    def to_yolo(self, img_width: int, img_height: int) -> List[float]:\n",
    "        x_cen = self.x1 + self.width/2\n",
    "        y_cen = self.y1 + self.height/2\n",
    "        x_cen = x_cen / img_width\n",
    "        y_cen = y_cen / img_height\n",
    "        width = self.width / img_width\n",
    "        height = self.height / img_height\n",
    "        return [x_cen, y_cen, width, height]\n",
    "    \n",
    "    def draw(self, img: ArrayLike, color: tuple = (255, 0, 0)) -> ArrayLike:\n",
    "        img = cv2.rectangle(img, self.pt1, self.pt2, color, 2)\n",
    "        return img\n",
    "    \n",
    "class Segment:\n",
    "    def __init__(self, input_annot: List[float | int], label: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_annot(list): Segmentation mask points in form of \"x1 y1 x2 y2 ... xn yn\"\n",
    "            label(int): The digit denoting the label of the item.\n",
    "        \"\"\"\n",
    "        self.input_annot = input_annot\n",
    "        self.pts = self.chunk(input_annot)\n",
    "        self.label = label\n",
    "    \n",
    "    def chunk(self, arr: List) -> List[ArrayLike]:\n",
    "        return [np.array(arr[i:i + 2]).reshape((-1,1,2)).astype(np.int32) for i in range(0, len(arr), 2)]\n",
    "\n",
    "    def segment_to_yolo(self, img_w, img_h):\n",
    "        text = \"\"\n",
    "        for i, p in enumerate(self.input_annot):\n",
    "            if i % 2 == 0: # x points / img_w\n",
    "                text += f\" {p/img_w:.3f}\"\n",
    "            else: # y points / img_h\n",
    "                text += f\" {p/img_h:.3f}\"\n",
    "        return text\n",
    "    \n",
    "    def get_bbox(self) -> Bbox:\n",
    "        Xs = [int(item) for i, item in enumerate(self.input_annot) if i%2 == 0]\n",
    "        Ys = [int(item) for i, item in enumerate(self.input_annot) if i%2 == 1]\n",
    "        x1, y1 = max(Xs), max(Ys)\n",
    "        x2, y2 = min(Xs), min(Ys)\n",
    "        bbox = Bbox([x1, y1, x2, y2], self.label)\n",
    "        return bbox\n",
    "    \n",
    "    def draw(self, img: ArrayLike, color: tuple = (0, 255, 0), draw_bbox = True) -> ArrayLike:\n",
    "        img = cv2.drawContours(img, self.pts, -1, color, 3)\n",
    "        bbox: Bbox = self.get_bbox()\n",
    "        if draw_bbox:\n",
    "            img = bbox.draw(img, color=color)\n",
    "        return img\n",
    "\n",
    "    \n",
    "class ImageAnnot:\n",
    "    # Fixme: Adapt the framework for training bbox annotated project. right now it is decent for segmentation project.\n",
    "    # Decouple Segment with Bbox.\n",
    "    def __init__(self, img_path: str | PosixPath):\n",
    "        \"\"\"\n",
    "        img_path(str | pathlib.PosixPath): image path\n",
    "        \n",
    "        \"\"\"\n",
    "        self.img_path = Path(img_path)\n",
    "        assert self.img_path.is_file()\n",
    "        self.name = self.img_path.name\n",
    "        self.segments = []\n",
    "        self.img_w, self.img_h = self.get_img_size()\n",
    "    \n",
    "    def get_img_size(self):\n",
    "        img = cv2.imread(self.img_path.as_posix())\n",
    "        return img.shape[1], img.shape[0]\n",
    "        \n",
    "    def add_segment(self, segment: Segment) -> None:\n",
    "        self.segments.append(segment)\n",
    "\n",
    "    def get_yolo_format(self, only_bboxes=True):\n",
    "        \"\"\"\n",
    "        the first five numbers still encode the class index and \n",
    "        bounding box information. The rest of the numbers encode \n",
    "        the boundary of the object that we are trying to segment. \n",
    "        Starting from the 6th number, we have space-separated \n",
    "        x-y coordinates for each point on the boundary of the \n",
    "        object for the segmentation mask.\n",
    "        \n",
    "        \"\"\"\n",
    "        temp = \"\"\n",
    "        for i, item in enumerate(self.segments):\n",
    "            label = item.label\n",
    "            x_cen, y_cen, w, h = item.get_bbox().to_yolo(self.img_w, self.img_h)\n",
    "            temp = f\"{label:.3f} {x_cen:.3f} {y_cen:.3f} {w:.3f} {h:.3f}\"\n",
    "            \n",
    "            if not only_bboxes:\n",
    "                segment_txt = item.segment_to_yolo(self.img_w, self.img_h)\n",
    "                temp += segment_txt\n",
    "\n",
    "            if i != len(self.segments)-1:\n",
    "                temp += '\\n'\n",
    "        return temp\n",
    "\n",
    "    def save_labels(self, save_path: str = \"base_dir\", train: bool = True, only_bboxes: bool = True):\n",
    "        output = self.get_yolo_format(only_bboxes=only_bboxes)\n",
    "        file_name = self.img_path.stem\n",
    "        \n",
    "        if train:\n",
    "            img_path = join(save_path, 'images', 'train')\n",
    "            label_path = join(save_path, 'labels', 'train')\n",
    "        else:\n",
    "            img_path = join(save_path, 'images', 'val')\n",
    "            label_path = join(save_path, 'labels', 'val')\n",
    "\n",
    "        makedirs(label_path, exist_ok=True)\n",
    "        makedirs(img_path, exist_ok=True)\n",
    "        \n",
    "        label_path = join(label_path, file_name + '.txt')\n",
    "        copy2(self.img_path.as_posix(), img_path)\n",
    "        with open(label_path, 'w') as file:\n",
    "            file.write(output)\n",
    "        \n",
    "    def get_coco_format(self):\n",
    "        pass\n",
    "\n",
    "    def img_show(self, color: tuple = (0, 255, 0)):\n",
    "        img = cv2.imread(self.img_path.as_posix())\n",
    "        img = cv2.cvtColor(img, 4)\n",
    "        for segment in self.segments:\n",
    "            img = segment.draw(img, color=color, draw_bbox=True)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caefcb0c-e8d8-4069-b4ad-5fc67bbeef62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating the frames: 100%|█████████████████████████████████████████████████████████| 178/178 [00:27<00:00,  6.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate the images before any process for annotations.\n",
    "# Demonstrate for both segmentation and detection at once\n",
    "\n",
    "\"\"\"\n",
    "json file:\n",
    "{\n",
    "    '/path/to/image_name.png':\n",
    "        [\n",
    "            {\n",
    "                'bbox': [x1, y1, x2, y2],\n",
    "                'segmentation': [x1 y1 x2 y2 ... xn yn],\n",
    "                'label': 'ball'\n",
    "            },\n",
    "            {\n",
    "                'bbox': [x1, y1, x2, y2],\n",
    "                'segmentation': [x1 y1 x2 y2 ... xn yn],\n",
    "                'label': 'ball'\n",
    "            }\n",
    "        ]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def cvat_prepare_images_annots(data_file: str, video_file: str, output_path: str, only_bboxes: bool = False):\n",
    "    assert os.path.isfile(data_file), f\"the file {data_file} does not exist\"\n",
    "    data = open(data_file).read()\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    assert cap.isOpened(), \"video is not accessible\"\n",
    "    output_path = join(output_path, 'images', 'train')\n",
    "    makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Read tags and extract the annotated frames.\n",
    "    bs_data = BeautifulSoup(data, \"xml\")\n",
    "    image_tags = bs_data.find_all('track')\n",
    "    print(len(image_tags))\n",
    "    annots_tags = [i for i in image_tags if i.polygon]\n",
    "    img_annots = []\n",
    "    \n",
    "    for img in tqdm(annots_tags, desc='generating the frames'):\n",
    "        fno = int(img['id'])\n",
    "        file_name = f'{Path(video_file).stem}_frame_{fno}'\n",
    "        file_path = join(output_path, file_name+'.png')\n",
    "        if not Path(file_path).is_file():\n",
    "            cap.set(1, fno)\n",
    "            status, frame = cap.read()\n",
    "            cv2.imwrite(file_path, frame)\n",
    "            \n",
    "        img_annot = ImageAnnot(file_path)\n",
    "        # Convert to yolo\n",
    "        polygons = [tag for tag in img.children if tag.name == 'polygon']\n",
    "        for poly in polygons:\n",
    "            points = poly['points']\n",
    "            points = [int(float(item)) for item in points.replace(';', ' ').replace(',', ' ').split(' ')]\n",
    "            segment = Segment(points, label=1)\n",
    "            img_annot.add_segment(segment)\n",
    "\n",
    "        img_annot.save_labels(save_path=output_path, train=True, only_bboxes=only_bboxes)\n",
    "\n",
    "# data_file = '../input/videos/train/annotations/8.xml'\n",
    "# video_file = '../input/videos/train/videos/8.mp4'\n",
    "# output_path = '../new/8'\n",
    "\n",
    "# cvat_prepare_images_annots(data_file=data_file , video_file=video_file, output_path= output_path, only_bboxes=True)\n",
    "\n",
    "data_file = '../input/videos/train/annotations/9.xml'\n",
    "video_file = '../input/videos/train/videos/9.webm'\n",
    "output_path = '../new/9'\n",
    "\n",
    "cvat_prepare_images_annots(data_file=data_file , video_file=video_file, output_path= output_path, only_bboxes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb19d9b-550c-4b9b-ba62-b74d5a839486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b07d0a-bc32-476a-b1d7-782db1026002",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001\n",
      "319\n"
     ]
    }
   ],
   "source": [
    "xml = '../input/videos/8.xml'\n",
    "vid = '../input/videos/8.mp4'\n",
    "\n",
    "with open(xml, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# the beautifulsoup parser, storing\n",
    "# the returned object \n",
    "bs_data = BeautifulSoup(data, \"xml\")\n",
    " \n",
    "# Finding all instances of tag \n",
    "# `unique`\n",
    "images = bs_data.find_all('image')\n",
    "annotated_images = [i for i in images if i.polygon is not None]\n",
    "print(len(images))\n",
    "print(len(annotated_images))\n",
    "\n",
    "\n",
    "t = annotated_images[0]\n",
    "width = t['width']\n",
    "height = t['height']\n",
    "frame_id = t.id\n",
    "points = t.polygon['points']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "745c6064-223a-4dfe-ac15-dd9f9477a2af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<image height=\"1080\" id=\"15050\" name=\"frame_015050\" width=\"1920\">\n",
       "<polygon label=\"ball\" occluded=\"0\" points=\"525.30,589.54;524.71,579.28;524.71,574.58;525.59,569.89;527.65,565.78;530.87,562.26;533.81,558.16;535.86,554.05;540.55,552.88;544.95,551.70;549.36,550.82;554.05,550.82;558.74,551.12;561.68,554.64;565.49,557.57;568.72,560.80;570.18,565.78;571.06,570.48;572.24,574.88;571.94,579.57;571.65,584.26;570.77,589.25;569.30,593.94;568.13,598.34;566.37,602.74;562.56,605.38;558.16,606.85;553.46,608.61;549.06,610.08;544.07,611.25;539.38,611.54;534.69,610.37;531.75,606.85;529.99,602.74;527.65,598.64\" source=\"manual\" z_order=\"0\">\n",
       "</polygon>\n",
       "</image>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce36e4e6-8237-41b6-9895-db29fe89546d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3955\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "with open('../input/annotations.xml') as file:\n",
    "    data = file.read()\n",
    "\n",
    "bs_data = BeautifulSoup(data, \"xml\")\n",
    "\n",
    "images = bs_data.find_all('image')\n",
    "annotated_images = [i for i in images if i.polygon is not None]\n",
    "print(len(images))\n",
    "print(len(annotated_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7889f8a9-3d77-4bb2-8f77-05c360e66436",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<polygon label=\"ball\" occluded=\"0\" points=\"466.10,131.80;463.98,129.67;461.85,127.73;460.79,125.25;460.61,122.60;461.68,120.12;463.09,117.82;465.21,116.05;467.51,114.46;470.52,113.58;473.53,114.29;476.00,115.52;478.13,117.65;480.42,119.42;481.49,121.89;481.13,124.54;479.19,126.67;476.36,127.73;473.53,127.55;470.87,127.73;470.17,130.38;468.04,132.33;465.39,132.50\" source=\"manual\" z_order=\"0\">\n",
       " </polygon>,\n",
       " <polygon label=\"ball\" occluded=\"0\" points=\"467.52,186.20;460.19,184.37;453.58,182.90;445.15,181.80;437.81,179.23;432.31,175.93;427.54,171.17;426.81,164.56;430.11,159.43;435.98,155.76;442.58,154.29;450.65,152.46;456.15,152.09;463.49,152.09;470.09,153.19;476.32,153.19;482.93,152.83;490.63,152.46;496.50,152.46;504.20,152.83;509.70,155.03;515.20,157.96;519.24,162.00;521.80,167.86;522.17,174.83;521.07,180.70;515.94,186.20;508.23,189.50;502.00,192.07;495.76,193.91;490.26,194.64;484.03,196.11;478.16,196.11;472.29,193.17\" source=\"manual\" z_order=\"0\">\n",
       " </polygon>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2pts = lambda text_points: [int(float(item)) for item in [text_points.replace(';', ' ').replace(',', ' ').split(' ')]] \n",
    "find_children = lambda tag, name: [(name, child['label'], child['points']) for child in tag.children if child.name == name]\n",
    "find_children(annotated_images[-1], 'polygon')\n",
    "boxes = find_children(image, 'box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ff25702-e5d0-4608-a5ea-b4931039e151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<image height=\"720\" id=\"2651\" name=\"frame_002651\" width=\"1280\">\n",
       "<polygon label=\"ball\" occluded=\"0\" points=\"466.10,131.80;463.98,129.67;461.85,127.73;460.79,125.25;460.61,122.60;461.68,120.12;463.09,117.82;465.21,116.05;467.51,114.46;470.52,113.58;473.53,114.29;476.00,115.52;478.13,117.65;480.42,119.42;481.49,121.89;481.13,124.54;479.19,126.67;476.36,127.73;473.53,127.55;470.87,127.73;470.17,130.38;468.04,132.33;465.39,132.50\" source=\"manual\" z_order=\"0\">\n",
       "</polygon>\n",
       "<polygon label=\"ball\" occluded=\"0\" points=\"467.52,186.20;460.19,184.37;453.58,182.90;445.15,181.80;437.81,179.23;432.31,175.93;427.54,171.17;426.81,164.56;430.11,159.43;435.98,155.76;442.58,154.29;450.65,152.46;456.15,152.09;463.49,152.09;470.09,153.19;476.32,153.19;482.93,152.83;490.63,152.46;496.50,152.46;504.20,152.83;509.70,155.03;515.20,157.96;519.24,162.00;521.80,167.86;522.17,174.83;521.07,180.70;515.94,186.20;508.23,189.50;502.00,192.07;495.76,193.91;490.26,194.64;484.03,196.11;478.16,196.11;472.29,193.17\" source=\"manual\" z_order=\"0\">\n",
       "</polygon>\n",
       "<box label=\"ball\" occluded=\"0\" source=\"manual\" xbr=\"502.69\" xtl=\"397.43\" ybr=\"146.08\" ytl=\"118.94\" z_order=\"0\">\n",
       "</box>\n",
       "</image>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in annotated_images[-1].find_all('polygon')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e058b48e-2fd5-41b0-9fe8-7a3a4deb8bea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[525,\n",
       " 589,\n",
       " 524,\n",
       " 579,\n",
       " 524,\n",
       " 574,\n",
       " 525,\n",
       " 569,\n",
       " 527,\n",
       " 565,\n",
       " 530,\n",
       " 562,\n",
       " 533,\n",
       " 558,\n",
       " 535,\n",
       " 554,\n",
       " 540,\n",
       " 552,\n",
       " 544,\n",
       " 551,\n",
       " 549,\n",
       " 550,\n",
       " 554,\n",
       " 550,\n",
       " 558,\n",
       " 551,\n",
       " 561,\n",
       " 554,\n",
       " 565,\n",
       " 557,\n",
       " 568,\n",
       " 560,\n",
       " 570,\n",
       " 565,\n",
       " 571,\n",
       " 570,\n",
       " 572,\n",
       " 574,\n",
       " 571,\n",
       " 579,\n",
       " 571,\n",
       " 584,\n",
       " 570,\n",
       " 589,\n",
       " 569,\n",
       " 593,\n",
       " 568,\n",
       " 598,\n",
       " 566,\n",
       " 602,\n",
       " 562,\n",
       " 605,\n",
       " 558,\n",
       " 606,\n",
       " 553,\n",
       " 608,\n",
       " 549,\n",
       " 610,\n",
       " 544,\n",
       " 611,\n",
       " 539,\n",
       " 611,\n",
       " 534,\n",
       " 610,\n",
       " 531,\n",
       " 606,\n",
       " 529,\n",
       " 602,\n",
       " 527,\n",
       " 598]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xys = t.polygon['points'].replace(';', ' ').replace(',', ' ').split(' ')\n",
    "xys = [int(float(item)) for item in xys]\n",
    "xys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01faff5c-ad19-493e-bba5-5e65efac936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.11",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
